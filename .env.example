# Model Configuration
PRIMARY_MODEL=qwen3-32b-awq
SECONDARY_MODEL=qwen3-14b-awq
CACHE_MODEL=qwen3-8b-q4

# Hardware
GPU_MEMORY_FRACTION=0.95
NUM_GPU_LAYERS=32
BATCH_SIZE=1

# Redis
REDIS_URL=redis://localhost:6379
CACHE_TTL=86400

# Cache Configuration
CACHE_DISTANCE_THRESHOLD=0.10
CACHE_TTL_GENERAL=86400
CACHE_TTL_TIMESENSITIVE=3600
CACHE_MAX_SIZE_MB=10000
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Fine-tuning
LORA_RANK=128
LORA_ALPHA=32
TRAINING_BATCH_SIZE=2
GRADIENT_ACCUMULATION_STEPS=4

# API
API_PORT=8000
API_HOST=0.0.0.0
MAX_TOKENS=4096

# Monitoring
LOG_LEVEL=INFO
METRICS_DB_URL=postgresql://user:pass@localhost/metrics

# Device
DEVICE_TYPE=server
TAILSCALE_IP=

# Model Paths
MODELS_DIR=./models
CHECKPOINTS_DIR=./checkpoints

# vLLM Configuration
VLLM_TENSOR_PARALLEL_SIZE=1
VLLM_GPU_MEMORY_UTILIZATION=0.90
